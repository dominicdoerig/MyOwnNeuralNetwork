{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dominic DÃ¶rig\n",
    "# 20.01.2018\n",
    "\n",
    "# my best Performance is 97.48%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy               # matrices\n",
    "import matplotlib.pyplot   # to plot arrays and matrices\n",
    "% matplotlib inline        \n",
    "import scipy.special       # expit() for the Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural Network class definition\n",
    "\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #initialise \n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, i: input, h: hidden, o: output\n",
    "        # pow(x,y) = x^y \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # train the network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate the signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output error is (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # hidden layer error is the ouput_errors, split by weights, recombined at hidden nodes\n",
    "        # Formel: Errors_hidden = weights_hidden,output (transponiert) * errors_output\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr*numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), \n",
    "                                     numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0-hidden_outputs)), \n",
    "                                       numpy.transpose(inputs))\n",
    "    pass\n",
    "    \n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        # Formel: X_hidden = W_input,hidden * I\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "\n",
    "# input_nodes = 28 * 28 = Amount of pixels per scan\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.12\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "\n",
    "training_data_file = open(\"C:/Users/dominic.doerig/OneDrive - Accenture/Trainings/Phyton/Neuronal Network/mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n",
    "    \n",
    "    # Duration of the training: 29sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"C:/Users/dominic.doerig/OneDrive - Accenture/Trainings/Phyton/Neuronal Network/mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9533\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)\n",
    "\n",
    "# Performance =  0.9533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   8,  149,  211,  217,  247,  259,  290,  320,  321,  340,  352,\n",
      "        362,  445,  449,  502,  543,  551,  565,  571,  582,  613,  629,\n",
      "        646,  658,  659,  684,  691,  707,  717,  720,  740,  741,  760,\n",
      "        810,  844,  846,  938,  939,  947,  950,  951,  956,  965, 1003,\n",
      "       1014, 1039, 1044, 1073, 1096, 1107, 1112, 1173, 1181, 1182, 1191,\n",
      "       1192, 1194, 1198, 1204, 1206, 1226, 1232, 1242, 1247, 1256, 1260,\n",
      "       1270, 1283, 1289, 1299, 1319, 1326, 1328, 1337, 1378, 1393, 1433,\n",
      "       1440, 1466, 1467, 1494, 1500, 1522, 1527, 1530, 1549, 1551, 1553,\n",
      "       1571, 1581, 1584, 1609, 1634, 1678, 1681, 1709, 1717, 1718, 1721,\n",
      "       1754, 1761, 1790, 1813, 1839, 1850, 1878, 1901, 1938, 1941, 1952,\n",
      "       1970, 1984, 2016, 2024, 2040, 2043, 2044, 2053, 2070, 2093, 2098,\n",
      "       2109, 2118, 2121, 2130, 2135, 2148, 2182, 2185, 2186, 2189, 2224,\n",
      "       2266, 2272, 2293, 2299, 2325, 2369, 2371, 2387, 2394, 2406, 2408,\n",
      "       2414, 2422, 2425, 2447, 2488, 2514, 2526, 2539, 2574, 2598, 2607,\n",
      "       2610, 2631, 2648, 2654, 2713, 2715, 2730, 2771, 2780, 2810, 2863,\n",
      "       2877, 2896, 2905, 2907, 2921, 2925, 2927, 2939, 2945, 2952, 2953,\n",
      "       2990, 2995, 3030, 3062, 3073, 3114, 3117, 3132, 3136, 3145, 3157,\n",
      "       3166, 3206, 3225, 3240, 3260, 3262, 3269, 3288, 3289, 3329, 3330,\n",
      "       3333, 3376, 3384, 3405, 3490, 3503, 3520, 3549, 3558, 3559, 3567,\n",
      "       3573, 3597, 3604, 3626, 3681, 3702, 3716, 3718, 3726, 3730, 3751,\n",
      "       3757, 3767, 3776, 3780, 3796, 3806, 3808, 3811, 3817, 3818, 3838,\n",
      "       3848, 3853, 3855, 3862, 3893, 3902, 3906, 3926, 3941, 3946, 3954,\n",
      "       3976, 3995, 4007, 4017, 4063, 4065, 4075, 4078, 4093, 4102, 4140,\n",
      "       4152, 4156, 4163, 4176, 4199, 4201, 4205, 4212, 4224, 4238, 4248,\n",
      "       4289, 4297, 4300, 4306, 4315, 4355, 4356, 4369, 4374, 4380, 4382,\n",
      "       4433, 4435, 4477, 4497, 4498, 4540, 4567, 4575, 4578, 4601, 4615,\n",
      "       4639, 4690, 4695, 4731, 4751, 4761, 4807, 4814, 4823, 4837, 4838,\n",
      "       4860, 4861, 4863, 4876, 4879, 4880, 4886, 4915, 4939, 4956, 4966,\n",
      "       4978, 4981, 4990, 4995, 4997, 5054, 5067, 5078, 5140, 5159, 5177,\n",
      "       5331, 5457, 5564, 5600, 5620, 5634, 5642, 5649, 5654, 5663, 5688,\n",
      "       5709, 5714, 5734, 5735, 5749, 5835, 5845, 5854, 5858, 5866, 5887,\n",
      "       5888, 5891, 5906, 5913, 5914, 5926, 5936, 5955, 5972, 5973, 5982,\n",
      "       6035, 6045, 6059, 6065, 6071, 6166, 6347, 6386, 6390, 6391, 6392,\n",
      "       6426, 6505, 6511, 6555, 6564, 6568, 6571, 6574, 6597, 6598, 6603,\n",
      "       6625, 6645, 6651, 6741, 6769, 6783, 7032, 7121, 7216, 7268, 7320,\n",
      "       7432, 7434, 7451, 7539, 7545, 7732, 7779, 7797, 7812, 7849, 7850,\n",
      "       7858, 7886, 7899, 7902, 7905, 7915, 7927, 7928, 7945, 7990, 8020,\n",
      "       8062, 8091, 8094, 8246, 8277, 8339, 8375, 8406, 8408, 8410, 8453,\n",
      "       8502, 8520, 8522, 8527, 8639, 8863, 9009, 9010, 9015, 9019, 9024,\n",
      "       9036, 9045, 9139, 9168, 9280, 9463, 9482, 9534, 9587, 9634, 9679,\n",
      "       9716, 9719, 9726, 9729, 9734, 9744, 9745, 9749, 9751, 9752, 9768,\n",
      "       9770, 9777, 9779, 9808, 9811, 9839, 9867, 9883, 9905, 9919, 9941,\n",
      "       9944, 9954, 9980, 9982, 9993], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# get index of wrongly recognized numbers\n",
    "index_wrongly_recognized = numpy.where(scorecard_array==0)\n",
    "print(index_wrongly_recognized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Value: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.30838581e-01],\n",
       "       [  2.85153211e-03],\n",
       "       [  5.65595767e-04],\n",
       "       [  2.36027431e-03],\n",
       "       [  5.08974074e-03],\n",
       "       [  2.74418483e-03],\n",
       "       [  4.63589996e-01],\n",
       "       [  1.70802155e-02],\n",
       "       [  4.38583672e-02],\n",
       "       [  2.51608958e-03]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDWQNIA5stwCyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23e55fea9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# query a wrongly recognized numbers\n",
    "\n",
    "# fill in one of the above indexes manually\n",
    "all_values = test_data_list[259].split(',')\n",
    "print(\"Real Value: \" + all_values[0])\n",
    "\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "\n",
    "n.query((numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01)\n",
    "\n",
    "# output signals:\n",
    "#   0: 0.831\n",
    "#   6: 0.464\n",
    "#   --> algorithm recognize a 0 instead of a 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Value: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.07971764e-03],\n",
       "       [  5.32765924e-01],\n",
       "       [  2.73020680e-04],\n",
       "       [  1.73061409e-02],\n",
       "       [  1.24072309e-03],\n",
       "       [  2.89518265e-03],\n",
       "       [  2.52211084e-03],\n",
       "       [  2.63398494e-01],\n",
       "       [  1.27675775e-02],\n",
       "       [  3.77249248e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23e561ddf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# query a wrongly recognized numbers\n",
    "\n",
    "# fill in one of the above indexes manually\n",
    "all_values = test_data_list[320].split(',')\n",
    "print(\"Real Value: \" + all_values[0])\n",
    "\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "\n",
    "n.query((numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01)\n",
    "\n",
    "# output signals:\n",
    "#   1: 0.533\n",
    "#   7: 0.263\n",
    "#   9: 0.377\n",
    "#   --> algorithm recognize a 1 instead of a 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
